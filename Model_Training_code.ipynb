{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63292633",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "IMAGE_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 40\n",
    "LEARNING_RATE = 1e-4\n",
    "dataset_dir = \"/home/anjalit/Crop_Disease_Detection/Crop__Disease\"\n",
    "checkpoint_dir = \"/home/anjalit/Crop_Disease_Detection/Crop__Disease/checkpoints\"\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "def get_data_generators(dataset_dir, image_size, batch_size, seed=42):\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rescale=1.0 / 255,\n",
    "        validation_split=0.2,\n",
    "        rotation_range=30,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        fill_mode=\"nearest\",\n",
    "        brightness_range=[0.7, 1.3],\n",
    "        channel_shift_range=50.0,\n",
    "    )\n",
    "\n",
    "    val_datagen = ImageDataGenerator(\n",
    "        rescale=1.0 / 255,\n",
    "        validation_split=0.2,\n",
    "    )\n",
    "\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        directory=dataset_dir,\n",
    "        target_size=(image_size, image_size),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=\"categorical\",\n",
    "        subset=\"training\",\n",
    "        shuffle=True,\n",
    "        seed=seed,\n",
    "    )\n",
    "\n",
    "    val_generator = val_datagen.flow_from_directory(\n",
    "        directory=dataset_dir,\n",
    "        target_size=(image_size, image_size),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=\"categorical\",\n",
    "        subset=\"validation\",\n",
    "        shuffle=False,\n",
    "        seed=seed,\n",
    "    )\n",
    "\n",
    "    return train_generator, val_generator\n",
    "\n",
    "def get_class_weights(generator):\n",
    "    class_weights = compute_class_weight(\n",
    "        class_weight=\"balanced\",\n",
    "        classes=np.unique(generator.classes),\n",
    "        y=generator.classes\n",
    "    )\n",
    "    return dict(enumerate(class_weights))\n",
    "\n",
    "class TransformerBlock(layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, mlp_dim):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.layernorm1 = layers.LayerNormalization()\n",
    "        self.mha = layers.MultiHeadAttention(num_heads=num_heads, key_dim=d_model)\n",
    "        self.layernorm2 = layers.LayerNormalization()\n",
    "        self.mlp = keras.Sequential([\n",
    "            layers.Dense(mlp_dim, activation=tf.nn.gelu),\n",
    "            layers.Dense(d_model)\n",
    "        ])\n",
    "\n",
    "    def call(self, x, training):\n",
    "        attn_output = self.mha(x, x, x)\n",
    "        out1 = self.layernorm1(x + attn_output)\n",
    "        mlp_output = self.mlp(out1)\n",
    "        return self.layernorm2(out1 + mlp_output)\n",
    "\n",
    "class MultiScaleVisionTransformer(tf.keras.Model):\n",
    "    def __init__(self, image_size=224, patch_sizes=[16, 32], num_layers=8, d_model=256, num_heads=8, mlp_dim=512, num_classes=7):\n",
    "        super(MultiScaleVisionTransformer, self).__init__()\n",
    "        self.image_size = image_size\n",
    "        self.patch_sizes = patch_sizes\n",
    "        self.num_layers = num_layers\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "        self.mlp_dim = mlp_dim\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        self.patch_projections = []\n",
    "        for size in patch_sizes:\n",
    "            self.patch_projections.append(layers.Conv2D(\n",
    "                filters=self.d_model,\n",
    "                kernel_size=size,\n",
    "                strides=size,\n",
    "                padding='valid'\n",
    "            ))\n",
    "\n",
    "        self.transformer_blocks = [TransformerBlock(self.d_model, self.num_heads, self.mlp_dim) for _ in range(self.num_layers)]\n",
    "        self.classifier_head = layers.Dense(self.num_classes, activation='softmax')\n",
    "\n",
    "    def call(self, x, training=False):\n",
    "        patch_embeddings = []\n",
    "        for proj in self.patch_projections:\n",
    "            patches = proj(x)\n",
    "            patches = tf.reshape(patches, [tf.shape(x)[0], -1, self.d_model])\n",
    "            patch_embeddings.append(patches)\n",
    "\n",
    "        x = tf.concat(patch_embeddings, axis=1)\n",
    "        for block in self.transformer_blocks:\n",
    "            x = block(x, training=training)\n",
    "\n",
    "        x = tf.reduce_mean(x, axis=1)\n",
    "        return self.classifier_head(x)\n",
    "\n",
    "def train_model():\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "\n",
    "    with strategy.scope():\n",
    "        train_generator, val_generator = get_data_generators(dataset_dir, IMAGE_SIZE, BATCH_SIZE)\n",
    "        num_classes = len(train_generator.class_indices)\n",
    "\n",
    "        model = MultiScaleVisionTransformer(\n",
    "            image_size=IMAGE_SIZE,\n",
    "            patch_sizes=[16, 32],\n",
    "            num_layers=8,\n",
    "            d_model=256,\n",
    "            num_heads=8,\n",
    "            mlp_dim=512,\n",
    "            num_classes=num_classes\n",
    "        )\n",
    "        model.build((None, IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "\n",
    "        optimizer = keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
    "        model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['accuracy', keras.metrics.Precision(), keras.metrics.Recall()]\n",
    "        )\n",
    "\n",
    "        x_batch, y_batch = next(train_generator)\n",
    "\n",
    "    class_weights = get_class_weights(train_generator)\n",
    "\n",
    "    class SaveModelCallback(tf.keras.callbacks.Callback):\n",
    "        def on_epoch_end(self, epoch, logs=None):\n",
    "            model.save(os.path.join(checkpoint_dir, f\"saved_model_epoch_{epoch + 1}\"), save_format=\"tf\")\n",
    "\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        validation_data=val_generator,\n",
    "        epochs=EPOCHS,\n",
    "        class_weight=class_weights,\n",
    "        callbacks=[\n",
    "            keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n",
    "            keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-6),\n",
    "            SaveModelCallback()\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return model, history, val_generator\n",
    "\n",
    "model, history, val_generator = train_model()\n",
    "\n",
    "model.save(\"multi_scale_vit_model.tf\")\n",
    "evaluation = model.evaluate(val_generator)\n",
    "\n",
    "def plot_training_history(history):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    ax1.plot(history.history['accuracy'], label='Train')\n",
    "    ax1.plot(history.history['val_accuracy'], label='Validation')\n",
    "    ax1.set_title('Model Accuracy')\n",
    "    ax1.legend()\n",
    "    ax2.plot(history.history['loss'], label='Train')\n",
    "    ax2.plot(history.history['val_loss'], label='Validation')\n",
    "    ax2.set_title('Model Loss')\n",
    "    ax2.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_training_history(history)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
